{
 "cells": [
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "!pip install -U pip\n",
    "!pip install -U seaborn\n",
    "!pip install -U pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Inicializaci칩n y carga de datos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Importanci칩n de librerias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, types\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from botocore.client import Config\n",
    "import ibm_boto3\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder, OrdinalEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.base import TransformerMixin, BaseEstimator\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2.  Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "RANDOM_STATE = 288"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Carga de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carga de datos\n",
    "df = pd.read_csv(body)\n",
    "df.set_index('empleado_id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Divisi칩n de los datos en train y set\n",
    "X, y = df.drop('target', axis=1), df['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. An치lisis inicial de los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Graduate          11598\n",
       "Masters            4361\n",
       "High School        2017\n",
       "Phd                 414\n",
       "Primary School      308\n",
       "Name: nivel_educacion, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X['nivel_educacion'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/Python-3.7-main/lib/python3.7/site-packages/sklearn/utils/validation.py:73: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  return f(**kwargs)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    11598\n",
       "2     4361\n",
       "1     2017\n",
       "5      460\n",
       "3      414\n",
       "4      308\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(LabelEncoder().fit_transform(SimpleImputer(strategy='constant', fill_value='missing').fit_transform(X[['nivel_educacion']]))).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_tf = Pipeline(steps=[\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "categorical_tf = Pipeline(steps=[\n",
    "    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n",
    "    ('ohe', OneHotEncoder(drop='first'))\n",
    "])\n",
    "\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('num', numeric_tf, ['horas_formacion', 'indice_desarrollo_ciudad']),\n",
    "        ('cat', categorical_tf, ['ultimo_nuevo_trabajo', 'tamano_compania', 'experiencia', 'educacion', 'universidad_matriculado', 'nivel_educacion', 'experiencia_relevante']),\n",
    "    ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=RANDOM_STATE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15326, 12), (15326,), (3832, 12), (3832,))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape, y_train.shape, X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>43</th>\n",
       "      <th>44</th>\n",
       "      <th>45</th>\n",
       "      <th>46</th>\n",
       "      <th>47</th>\n",
       "      <th>48</th>\n",
       "      <th>49</th>\n",
       "      <th>50</th>\n",
       "      <th>51</th>\n",
       "      <th>52</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.979049</td>\n",
       "      <td>0.788705</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.144332</td>\n",
       "      <td>-2.192565</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.778717</td>\n",
       "      <td>0.740098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.139472</td>\n",
       "      <td>0.659085</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.890717</td>\n",
       "      <td>0.659085</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15321</th>\n",
       "      <td>0.778717</td>\n",
       "      <td>0.740098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15322</th>\n",
       "      <td>-0.339804</td>\n",
       "      <td>0.553768</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15323</th>\n",
       "      <td>1.145993</td>\n",
       "      <td>0.740098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15324</th>\n",
       "      <td>-0.172860</td>\n",
       "      <td>-0.823449</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15325</th>\n",
       "      <td>0.795411</td>\n",
       "      <td>0.740098</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15326 rows 칑 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             0         1    2    3    4    5    6    7    8    9   ...   43  \\\n",
       "0      0.979049  0.788705  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "1      0.144332 -2.192565  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "2      0.778717  0.740098  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  1.0   \n",
       "3     -0.139472  0.659085  0.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "4     -0.890717  0.659085  1.0  0.0  0.0  0.0  0.0  0.0  1.0  0.0  ...  0.0   \n",
       "...         ...       ...  ...  ...  ...  ...  ...  ...  ...  ...  ...  ...   \n",
       "15321  0.778717  0.740098  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "15322 -0.339804  0.553768  0.0  0.0  0.0  1.0  0.0  0.0  1.0  0.0  ...  0.0   \n",
       "15323  1.145993  0.740098  0.0  1.0  0.0  0.0  0.0  0.0  0.0  1.0  ...  0.0   \n",
       "15324 -0.172860 -0.823449  1.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "15325  0.795411  0.740098  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  ...  0.0   \n",
       "\n",
       "        44   45   46   47   48   49   50   51   52  \n",
       "0      0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "1      0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "2      1.0  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  \n",
       "3      0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "4      0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "...    ...  ...  ...  ...  ...  ...  ...  ...  ...  \n",
       "15321  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "15322  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "15323  0.0  0.0  1.0  0.0  1.0  0.0  0.0  0.0  0.0  \n",
       "15324  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "15325  0.0  0.0  1.0  0.0  0.0  0.0  0.0  0.0  0.0  \n",
       "\n",
       "[15326 rows x 53 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(preprocessor.fit_transform(X_train).toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sparse2Array(BaseEstimator, TransformerMixin):\n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        return self\n",
    "    \n",
    "    def transform(self, X, y=None):\n",
    "        return X.toarray()\n",
    "    \n",
    "    def fit_transform(self, X, y=None):\n",
    "        return self.fit(X).transform(X)\n",
    "    \n",
    "\n",
    "class Clf(BaseEstimator):\n",
    "    \"\"\"Base model used to host classifiers on GridSearchCV\"\"\"\n",
    "    def __init__(self, estimator=DummyClassifier()):\n",
    "        self.estimator = estimator\n",
    "\n",
    "    def fit(self, X, y=None, **kwargs):\n",
    "        self.estimator.fit(X, y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X, y=None):\n",
    "        return self.estimator.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.estimator.predict_proba(X)\n",
    "\n",
    "    def score(self, X, y):\n",
    "        return self.estimator.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(19158, 53)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pca = PCA()\n",
    "X_preprocessed = pd.DataFrame(preprocessor.fit_transform(X).toarray())\n",
    "X_preprocessed.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x7f3d928f2610>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "pca.fit(X_preprocessed)\n",
    "pd.DataFrame({\n",
    "    'n_components': range(1, len(X_preprocessed.columns) + 1),\n",
    "    'variance': np.cumsum(pca.explained_variance_ratio_)*100         \n",
    "    }).set_index('n_components').plot(xticks=range(1, 53, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = make_pipeline(preprocessor, Sparse2Array(), PCA(), Clf())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = [{\n",
    "        'clf__estimator': [DummyClassifier()] # Este modelo nos sirve para comparar los resultados del resto respecto a la aleatoriedad\n",
    "    },{\n",
    "        'clf__estimator': [LogisticRegression()],\n",
    "        'clf__estimator__solver': ['sag', 'saga'],\n",
    "        'clf__estimator__max_iter': [100, 800], #default 100\n",
    "        'clf__estimator__penalty': ['l2', 'none'], #default l2\n",
    "        'pca__n_components': [30, 40, 52] # 52 = n_features before preprocessing\n",
    "     },{\n",
    "        'clf__estimator': [RandomForestClassifier()],\n",
    "        'clf__estimator__criterion': ['entropy', 'gini'], #default gini\n",
    "        'clf__estimator__n_estimators': [100, 150], #default 100\n",
    "        'pca__n_components': [30, 40, 52]\n",
    "    },{\n",
    "        'clf__estimator': [SVC()],\n",
    "        'clf__estimator__C': [1., 10.], # default 1.\n",
    "        'clf__estimator__gamma': ['scale', 'auto'], # default scale\n",
    "        'pca__n_components': [30, 40, 52]\n",
    "    }]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gs = GridSearchCV(pipe, param_grid, cv=3, n_jobs=-1, verbose=4, scoring='accuracy', return_train_score=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 49 candidates, totalling 147 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  17 tasks      | elapsed:    4.1s\n",
      "[Parallel(n_jobs=-1)]: Done  90 tasks      | elapsed:  1.1min\n",
      "[Parallel(n_jobs=-1)]: Done 147 out of 147 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3,\n",
       "             estimator=Pipeline(steps=[('columntransformer',\n",
       "                                        ColumnTransformer(transformers=[('num',\n",
       "                                                                         Pipeline(steps=[('scaler',\n",
       "                                                                                          StandardScaler())]),\n",
       "                                                                         ['horas_formacion',\n",
       "                                                                          'indice_desarrollo_ciudad']),\n",
       "                                                                        ('cat',\n",
       "                                                                         Pipeline(steps=[('imputer',\n",
       "                                                                                          SimpleImputer(fill_value='missing',\n",
       "                                                                                                        strategy='constant')),\n",
       "                                                                                         ('ohe',\n",
       "                                                                                          OneHotEncoder(drop='first'))]),\n",
       "                                                                         ['ultimo_nuevo_trabajo'...\n",
       "                          'pca__n_components': [30, 40, 52]},\n",
       "                         {'clf__estimator': [RandomForestClassifier()],\n",
       "                          'clf__estimator__criterion': ['entropy', 'gini'],\n",
       "                          'clf__estimator__n_estimators': [100, 150],\n",
       "                          'pca__n_components': [30, 40, 52]},\n",
       "                         {'clf__estimator': [SVC()],\n",
       "                          'clf__estimator__C': [1.0, 10.0],\n",
       "                          'clf__estimator__gamma': ['scale', 'auto'],\n",
       "                          'pca__n_components': [30, 40, 52]}],\n",
       "             return_train_score=True, scoring='accuracy', verbose=4)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(gs.cv_results_).sort_values('rank_test_score').reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>param_clf__estimator</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>mean_train_score</th>\n",
       "      <th>param_pca__n_components</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.776458</td>\n",
       "      <td>0.816293</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.776002</td>\n",
       "      <td>0.813259</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.775088</td>\n",
       "      <td>0.810257</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.773066</td>\n",
       "      <td>0.787583</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.772413</td>\n",
       "      <td>0.790715</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.772152</td>\n",
       "      <td>0.783766</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.769738</td>\n",
       "      <td>0.776360</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.769607</td>\n",
       "      <td>0.772021</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.769607</td>\n",
       "      <td>0.772021</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.769607</td>\n",
       "      <td>0.772021</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.769607</td>\n",
       "      <td>0.772021</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.769216</td>\n",
       "      <td>0.771141</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.769216</td>\n",
       "      <td>0.771173</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.769216</td>\n",
       "      <td>0.771141</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.769216</td>\n",
       "      <td>0.771173</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.768107</td>\n",
       "      <td>0.768759</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.768107</td>\n",
       "      <td>0.768759</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.768041</td>\n",
       "      <td>0.768759</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.768041</td>\n",
       "      <td>0.768759</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.767715</td>\n",
       "      <td>0.769118</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.767715</td>\n",
       "      <td>0.769118</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.767715</td>\n",
       "      <td>0.769151</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.767715</td>\n",
       "      <td>0.769118</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.767715</td>\n",
       "      <td>0.772087</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.767259</td>\n",
       "      <td>0.988027</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.766736</td>\n",
       "      <td>0.767846</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.766671</td>\n",
       "      <td>0.987505</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.766606</td>\n",
       "      <td>0.767715</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.766475</td>\n",
       "      <td>0.767846</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.766475</td>\n",
       "      <td>0.767748</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.766345</td>\n",
       "      <td>0.767911</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.766345</td>\n",
       "      <td>0.768009</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.766280</td>\n",
       "      <td>0.767943</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>LogisticRegression()</td>\n",
       "      <td>0.766214</td>\n",
       "      <td>0.767552</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.765040</td>\n",
       "      <td>0.987342</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.764714</td>\n",
       "      <td>0.985417</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.763996</td>\n",
       "      <td>0.880138</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.763931</td>\n",
       "      <td>0.998238</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.763017</td>\n",
       "      <td>0.862391</td>\n",
       "      <td>30</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.762169</td>\n",
       "      <td>0.766312</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.761647</td>\n",
       "      <td>0.998304</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.761190</td>\n",
       "      <td>0.998304</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.760864</td>\n",
       "      <td>0.998304</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.760603</td>\n",
       "      <td>0.998304</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.760538</td>\n",
       "      <td>0.998271</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.759951</td>\n",
       "      <td>0.998206</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>SVC()</td>\n",
       "      <td>0.758515</td>\n",
       "      <td>0.889110</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>RandomForestClassifier()</td>\n",
       "      <td>0.758189</td>\n",
       "      <td>0.998304</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>DummyClassifier()</td>\n",
       "      <td>0.625538</td>\n",
       "      <td>0.627365</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        param_clf__estimator  mean_test_score  mean_train_score  \\\n",
       "0                      SVC()         0.776458          0.816293   \n",
       "1                      SVC()         0.776002          0.813259   \n",
       "2                      SVC()         0.775088          0.810257   \n",
       "3                      SVC()         0.773066          0.787583   \n",
       "4                      SVC()         0.772413          0.790715   \n",
       "5                      SVC()         0.772152          0.783766   \n",
       "6                      SVC()         0.769738          0.776360   \n",
       "7       LogisticRegression()         0.769607          0.772021   \n",
       "8       LogisticRegression()         0.769607          0.772021   \n",
       "9       LogisticRegression()         0.769607          0.772021   \n",
       "10      LogisticRegression()         0.769607          0.772021   \n",
       "11      LogisticRegression()         0.769216          0.771141   \n",
       "12      LogisticRegression()         0.769216          0.771173   \n",
       "13      LogisticRegression()         0.769216          0.771141   \n",
       "14      LogisticRegression()         0.769216          0.771173   \n",
       "15      LogisticRegression()         0.768107          0.768759   \n",
       "16      LogisticRegression()         0.768107          0.768759   \n",
       "17      LogisticRegression()         0.768041          0.768759   \n",
       "18      LogisticRegression()         0.768041          0.768759   \n",
       "19      LogisticRegression()         0.767715          0.769118   \n",
       "20      LogisticRegression()         0.767715          0.769118   \n",
       "21      LogisticRegression()         0.767715          0.769151   \n",
       "22      LogisticRegression()         0.767715          0.769118   \n",
       "23                     SVC()         0.767715          0.772087   \n",
       "24  RandomForestClassifier()         0.767259          0.988027   \n",
       "25      LogisticRegression()         0.766736          0.767846   \n",
       "26  RandomForestClassifier()         0.766671          0.987505   \n",
       "27      LogisticRegression()         0.766606          0.767715   \n",
       "28      LogisticRegression()         0.766475          0.767846   \n",
       "29      LogisticRegression()         0.766475          0.767748   \n",
       "30      LogisticRegression()         0.766345          0.767911   \n",
       "31      LogisticRegression()         0.766345          0.768009   \n",
       "32      LogisticRegression()         0.766280          0.767943   \n",
       "33      LogisticRegression()         0.766214          0.767552   \n",
       "34  RandomForestClassifier()         0.765040          0.987342   \n",
       "35  RandomForestClassifier()         0.764714          0.985417   \n",
       "36                     SVC()         0.763996          0.880138   \n",
       "37  RandomForestClassifier()         0.763931          0.998238   \n",
       "38                     SVC()         0.763017          0.862391   \n",
       "39                     SVC()         0.762169          0.766312   \n",
       "40  RandomForestClassifier()         0.761647          0.998304   \n",
       "41  RandomForestClassifier()         0.761190          0.998304   \n",
       "42  RandomForestClassifier()         0.760864          0.998304   \n",
       "43  RandomForestClassifier()         0.760603          0.998304   \n",
       "44  RandomForestClassifier()         0.760538          0.998271   \n",
       "45  RandomForestClassifier()         0.759951          0.998206   \n",
       "46                     SVC()         0.758515          0.889110   \n",
       "47  RandomForestClassifier()         0.758189          0.998304   \n",
       "48         DummyClassifier()         0.625538          0.627365   \n",
       "\n",
       "   param_pca__n_components  \n",
       "0                       52  \n",
       "1                       40  \n",
       "2                       30  \n",
       "3                       40  \n",
       "4                       30  \n",
       "5                       52  \n",
       "6                       30  \n",
       "7                       52  \n",
       "8                       52  \n",
       "9                       52  \n",
       "10                      52  \n",
       "11                      52  \n",
       "12                      52  \n",
       "13                      52  \n",
       "14                      52  \n",
       "15                      40  \n",
       "16                      40  \n",
       "17                      40  \n",
       "18                      40  \n",
       "19                      40  \n",
       "20                      40  \n",
       "21                      40  \n",
       "22                      40  \n",
       "23                      40  \n",
       "24                      30  \n",
       "25                      30  \n",
       "26                      30  \n",
       "27                      30  \n",
       "28                      30  \n",
       "29                      30  \n",
       "30                      30  \n",
       "31                      30  \n",
       "32                      30  \n",
       "33                      30  \n",
       "34                      30  \n",
       "35                      30  \n",
       "36                      40  \n",
       "37                      52  \n",
       "38                      30  \n",
       "39                      52  \n",
       "40                      52  \n",
       "41                      40  \n",
       "42                      40  \n",
       "43                      40  \n",
       "44                      52  \n",
       "45                      40  \n",
       "46                      52  \n",
       "47                      52  \n",
       "48                     NaN  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results[['param_clf__estimator', 'mean_test_score', 'mean_train_score', 'param_pca__n_components']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
